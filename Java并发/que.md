1. 什么是线程池，如何使用？为什么要使用线程池？
    * 线程池就是事先将多个线程对象放到一个容器中，使用的时候就不用new线程而是直接去池中拿线程即可，节 省了开辟子线程的时间，提高了代码执行效率。
2. Java中的线程池共有几种？
    * newCachedThreadPool：不固定线程数量，且支持最大为Integer.MAX_VALUE的线程数量。【可缓存线程池】线程数无限制，有空闲线程则复用空闲线程，若无空闲线程则新建线程。一定程序减少频繁创建/销毁线程，减少系统开销。
    * newFixedThreadPool：固定线程数量的线程池。【定长线程池】可控制线程最大并发数（同时执行的线程数）。超出的线程会在队列中等待。
    * newSingleThreadExecutor：线程数量为1的FixedThreadPool:有且仅有一个工作线程执行任务。所有任务按照指定顺序执行，即遵循队列的入队出队规则。
    * newScheduledThreadPool。支持定时以指定周期循环执行任务
3. 线程池原理
    * 阻塞队列+HashSet
    * 如果正在运行的线程数 < coreSize，马上创建核心线程执行该task，不排队等待；
    * 如果正在运行的线程数 >= coreSize，把该task放入阻塞队列；
    * 如果队列已满 && 正在运行的线程数 < maximumPoolSize（线程池中最大线程数），创建新的非核心线程执行该task；
    * 如果队列已满 && 正在运行的线程数 >= maximumPoolSize，线程池调用handler的reject方法拒绝本次提交。
    * 理解记忆：1-2-3-4对应（核心线程->阻塞队列->非核心线程->handler拒绝提交）
4. 怎么理解无界队列和有界队列？
    * 有界队列
      * 初始的poolSize < corePoolSize，提交的runnable任务，会直接做为new一个Thread的参数，立马执行 。 
      * 当提交的任务数超过了corePoolSize，会将当前的runable提交到一个block queue中。 
      * 有界队列满了之后，如果poolSize < maximumPoolsize时，会尝试new 一个Thread的进行救急处理，立马执行对应的runnable任务。 
      * 如果3中也无法处理了，就会走到第四步执行reject操作。
    * 无界队列
      * 与有界队列相比，除非系统资源耗尽，否则无界的任务队列不存在任务入队失败的情况。
      * 当有新的任务到来，系统的线程数小于corePoolSize时，则新建线程执行任务。
      * 当达到corePoolSize后，就不会继续增加，若后续仍有新的任务加入，而没有空闲的线程资源，则任务直接进入队列等待。
      * 若任务创建和处理的速度差异很大，无界队列会保持快速增长，直到耗尽系统内存。
      * 当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略。
5. synchronized的原理？
    * 所谓锁的升级、降级，就是 JVM 优化 synchronized 运行的机制，当 JVM 检测到不同的竞争状况时，会自动切换到适合的锁实现，这种切换就是锁的升级、降级。
    * 偏斜锁（Biased Locking）、轻量级锁和重量级锁，
    * 当没有竞争出现时，默认会使用偏斜锁。JVM 会利用 CAS 操作，在对象头上的 Mark Word 部分设置线程 ID，以表示这个对象偏向于当前线程，所以并不涉及真正的互斥锁。这样做的假设是基于在很多应用场景中，大部分对象生命周期中最多会被一个线程锁定，使用偏斜锁可以降低无竞争开销。
    * 如果有另外的线程试图锁定某个已经被偏斜过的对象，JVM 就需要撤销（revoke）偏斜锁，并切换到轻量级锁实现。轻量级锁依赖 CAS 操作 Mark Word 来试图获取锁，如果重试成功，就使用普通的轻量级锁；否则，进一步升级为重量级锁（可能会先进行自旋锁升级，如果失败再尝试重量级锁升级）。
6. Synchronized优化后的锁机制简单介绍一下，包括自旋锁、偏向锁、轻量级锁、重量级锁？
    * 自旋锁：线程自旋说白了就是让cpu在做无用功，比如：可以执行几次for循环，可以执行几条空的汇编指令，目的是占着CPU不放，等待获取锁的机会。如果旋的时间过长会影响整体性能，时间过短又达不到延迟阻塞的目的。
    * 偏向锁  偏向锁就是一旦线程第一次获得了监视对象，之后让监视对象“偏向”这个线程，之后的多次调用则可以避免CAS操作，说白了就是置个变量，如果发现为true则无需再走各种加锁/解锁流程。无实际竞争，且将来只有第一个申请锁的线程会使用锁。
    * 轻量级锁：轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁竞争用的时候，偏向锁就会升级为轻量级锁；无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。
    * 重量级锁：有实际竞争，且锁竞争时间长。重量锁在JVM中又叫对象监视器（Monitor），它很像C中的Mutex，除了具备Mutex(0|1)互斥的功能，它还负责实现了Semaphore(信号量)的功能，也就是说它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。
7. 谈谈对Synchronized关键字涉及到的类锁，方法锁，重入锁的理解？
    * 修饰静态方法获取的是类锁
    * 修饰普通方法或代码块获取的是对象锁。这种机制确保了同一时刻对于每一个类实例，其所有声明为 synchronized 的成员函数中至多只有一个处于可执行状态，从而有效避免了类成员变量的访问冲突。
8. wait、sleep的区别和notify运行过程。
    * wait、sleep的区别
      * 最大的不同是在等待时 wait 会释放锁，而 sleep 一直持有锁。wait 通常被用于线程间交互，sleep 通常被用于暂停执行。
      * “sleep是Thread类的方法,wait是Object类中定义的方法”。尽管这两个方法都会影响线程的执行行为，但是本质上是有区别的。
      * Thread.sleep不会导致锁行为的改变，如果当前线程是拥有锁的，那么Thread.sleep不会让线程释放锁。如果能够帮助你记忆的话，可以简单认为和锁相关的方法都定义在Object类中，因此调用Thread.sleep是不会影响锁的相关行为。
      * Thread.sleep和Object.wait都会暂停当前的线程，对于CPU资源来说，不管是哪种方式暂停的线程，都表示它暂时不再需要CPU的执行时间。OS会将执行时间分配给其它线程。区别是，调用wait后，需要别的线程执行notify/notifyAll才能够重新获得CPU执行时间。
      * 线程的状态参考 Thread.State的定义。新创建的但是没有执行（还没有调用start())的线程处于“就绪”，或者说Thread.State.NEW状态。
      * Thread.State.BLOCKED（阻塞）表示线程正在获取锁时，因为锁不能获取到而被迫暂停执行下面的指令，一直等到这个锁被别的线程释放。BLOCKED状态下线程，OS调度机制需要决定下一个能够获取锁的线程是哪个，这种情况下，就是产生锁的争用，无论如何这都是很耗时的操作。
    * notify运行过程
      * 当线程A（消费者）调用wait()方法后，线程A让出锁，自己进入等待状态，同时加入锁对象的等待队列。 线程B（生产者）获取锁后，调用notify方法通知锁对象的等待队列，使得线程A从等待队列进入阻塞队列。 线程A进入阻塞队列后，直至线程B释放锁后，线程A竞争得到锁继续从wait()方法后执行。
9. volatile原理。
    * 解决可见性有序性问题
    * 对volatile变量的单次读/写操作可保证原子性的，如long和double类型变量，但是并不能保证i++这种操作的原子性，因为本质上i++是读、写两次操作。原子性是指一个线程的操作是不能被其他线程打断，同一时间只有一个线程对一个变量进行操作。三个步骤：内存到寄存器、寄存器自增、写回内存
    * volatile也是互斥同步的一种实现，不过它非常的轻量级。
    * 防止CPU指令重排序
      * 指令重排序是指指令乱序执行，即在条件允许的情况下直接运行当前有能力立即执行的后续指令，避开为获取一条指令所需数据而造成的等待，通过乱序执行的技术提供执行效率。
      * 指令重排序会在被volatile修饰的变量的赋值操作前，添加一个内存屏障，指令重排序时不能把后面的指令重排序移到内存屏障之前的位置。
    * 保证被volatile修饰的变量对所有线程都是可见的
      * 每个线程会 有自己的工作内存，工作内存里保存了线程所使用到的变量在主内存里的副本拷贝，线程对变量的操作只能在工作内存里进行，而不能直接读写主内存，当然不同内存之间也 无法直接访问对方的工作内存，
      * 被volatile修饰的变量在工作内存修改后会被强制写回主内存，其他线程在使用时也会强制从主内存刷新，这样就保证了一致性。
    * 可见性原理
      * 缓存一致性原理：当CPU写数据时，如果操作的数据是共享变量，就会通知其他CPU该变量的缓存无效，当需要使用时，需要到内存重新读取。
      * 嗅探：每个CPU会通过嗅探在总线上的数据和自己的缓存比较，如果发现变量的缓存地址被修改，就将缓存置为无效
      * 总线风暴：由于每个CPU需要不断地嗅探和CAS比较，容易占满整个带宽
10. synchronized 和 volatile 关键字的作用和区别。
    * volatile 本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需从主存中读取；
    * synchronized则是锁定当前变量，只有当前线程可以访问该变量，其它线程被阻塞住。
    * 区别
      * volatile 仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的。
      * volatile 仅能实现变量的修改可见性，并不能保证原子性；synchronized 则可以保证变量的修改可见性和原子性。
      * volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞。
11. 多线程的使用场景
    * 使用多线程并不是为了提高效率，而是使得CPU能同时处理多个事件。
    * 为了不阻塞主线程,启动其他线程来做事情,比如APP中的耗时操作都不在UI线程中做。
    * 某种虽然优先级很低的服务，但是却要不定时去做。比如Jvm的垃圾回收。
    * 某种虽然优先级很低的服务，但是却要不定时去做。比如Jvm的垃圾回收。
12. CopyOnWriteArrayList的了解。
    * Copy-On-Write 是什么？
      * 在计算机中就是当你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉。
    * CopyOnWriteArrayList这是一个ArrayList的线程安全的变体，CopyOnWriteArrayList 底层实现添加的原理是先copy出一个容器(可以简称副本)，再往新的容器里添加这个新的数据，最后把新的容器的引用地址赋值给了之前那个旧的的容器地址，但是在添加这个数据的期间，其他线程如果要去读取数据，仍然是读取到旧的容器里的数据。
    * 缺点
      * 内存占有问题:很明显，两个数组同时驻扎在内存中，如果实际应用中，数据比较多，而且比较大的情况下，占用内存会比较大，针对这个其实可以用ConcurrentHashMap来代替。
      * 数据一致性:CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器.
13. ConcurrentHashMap加锁机制是什么，详细说一下？
    * 哈希表
    * 容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术，
    * 首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。
    * ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。一旦初始化以后，它是不可以扩容的。其中的每个 Segment 很像 HashMap，
    * Java8 ConcurrentHashMap,抛弃了原有的 Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性。结构上和 Java8 的 HashMap（数组+链表+红黑树） 基本上一样，不过它要保证线程安全性
14. 线程死锁的4个条件？
    * AB两个线程由于互相持有对方需要的锁，而发生的阻塞现象，我们称为死锁。
    * 互斥条件：一个资源每次只能被一个线程使用
    * 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
    * 不剥夺条件：线程已获得的资源，在未使用完之前，不能强行剥夺。
    * 循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系。
15. CAS介绍？
    * CAS，Compare and Swap即比较并交换，
    * 如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了
16. 进程和线程的区别？
    * 一个程序至少有一个进程,一个进程至少有一个线程
    * 进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。
    * 一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行。
    * 进程是资源分配的基本单位，线程是CPU调度执行的最小允许单位
    * 进程切换要保存当前CPU环境和建立新的CPU环境，线程切换只需要保存虚拟机栈和程序计数器
    * 进程间的资源和地址相互独立，同一进程的线程共享本进程的资源和地址
    * 一个进程崩溃不会影响其他进程，一个线程崩溃容易整个进程挂掉
    * 
17. 什么导致线程阻塞？
    * 阻塞指的是暂停一个线程的执行以等待某个条件发生（如某资源就绪）
    * sleep() 方法：sleep() 允许 指定以毫秒为单位的一段时间作为参数，它使得线程在指定的时间内进入阻塞状态，不能得到CPU 时间，指定的时间一过，线程重新进入可执行状态。 典型地，sleep() 被用在等待某个资源就绪的情形：测试发现条件不满足后，让线程阻塞一段时间后重新测试，直到条件满足为止。
    * yield() 方法：yield() 使得线程放弃当前分得的 CPU 时间，但是不使线程阻塞，即线程仍处于可执行状态，随时可能再次分得 CPU 时间。调用 yield() 的效果等价于调度程序认为该线程已执行了足够的时间从而转到另一个线程。
    * wait() 和 notify() 方法：两个方法配套使用，wait() 使得线程进入阻塞状态，它有两种形式，一种允许指定以毫秒为单位的一段时间作为参数，另一种没有参数，前者当对应的 notify() 被调用或者超出指定时间时线程重新进入可执行状态，后者则必须对应的 notify() 被调用。
18. 线程的生命周期
    * NEW：创建状态，线程创建之后，但是还未启动。
    * RUNNABLE：运行状态，处于运行状态的线程，但有可能处于等待状态，例如等待CPU、IO等。
    * WAITING：等待状态，一般是调用了wait()、join()、LockSupport.spark()等方法。
    * TIMED_WAITING：超时等待状态，也就是带时间的等待状态。一般是调用了wait(time)、join(time)、LockSupport.sparkNanos()、LockSupport.sparkUnit()等方法。
    * BLOCKED：阻塞状态，等待锁的释放，例如调用了synchronized增加了锁。
    * TERMINATED：终止状态，一般是线程完成任务后退出或者异常终止。
    * 线程进入RUNNABLE运行态一般分为五种情况：
      *  线程调用sleep(time)后结束了休眠时间
      *  线程调用的阻塞IO已经返回，阻塞方法执行完毕
      *  线程成功的获取了资源锁
      *  线程正在等待某个通知，成功的获得了其他线程发出的通知
      *  线程处于挂起状态，然后调用了resume()恢复方法，解除了挂起。
    * 线程进入BLOCKED阻塞态一般也分为五种情况：
      * 线程调用sleep()方法主动放弃占有的资源
      * 线程调用了阻塞式IO的方法，在该方法返回前，该线程被阻塞。
      * 线程视图获得一个资源锁，但是该资源锁正被其他线程锁持有。
      * 线程调度器调用suspend()方法将该线程挂起
19. 优缺点
  * 充分利用多核cpu功能，提高性能
  * 拆分业务，提高系统处理能力
  * 缺点：会引发内存泄漏、上下文切换、线程安全、死锁等
20. 线程安全
  * 原子性——一组操作要么都执行要么都不执行——线程切换——Atomic原子类，synchronized，Lock
  * 可见性——一个线程对共享变量的修改，另一个线程是可见的——synchronized，Lock，volatile
  * 有序性——程序执行的顺序按代码的先后顺序执行——Happens-Before
21. 并发和并行
  * 并发指同一时间段，多个任务按时间片轮转执行。并行指单位时间内，多个任务被多个处理器同时执行。
  * eg. 8-9点，我洗脸刷牙吃饭->并发，我左手洗脸右手刷牙->并行。
22. 多线程
  * 内容：一个进程并发的执行多个线程，每个线程执行不同的内容
  * 优势：采用cpu时间片轮询的模式，提高资源利用率
  * 劣势：
    * 线程切换引起执行速度的下降
    * 大量线程会占用大量内存
    * 对共享资源的访问会带来死锁等问题。
23. 守护线程和用户线程
  * 守护线程：运行在后台，为前台进程服务，比如GC线程
  * 用户线程：运行在前台，执行具体的任务，比如main（）
24. 进程间通信方式
  * 管道 Pipes：只能用于父子进程或兄弟进程间的通信；
  * 有名管道 Name Pipes：遵循FIFO，能实现任意两个进程通信；
  * 信号 Signal：通知接收进程某个事件已发生；
  * 消息队列 Message Queuing：遵循FIFO，存放内核中，能实现消息的随机查询。克服了信号承载信息少，管道只能承载无格式字节流和缓冲区大小受限问题。
  * 信号量 Semaphores：就是计数器，解决进程间同步竞争，用于多进程的共享资源访问。
  * 共享内存 Shared Memory：使多进程可以同时访问同一块内存空间，不同进程能看到其他进程对共享资源的操作。
  * 套接字 Socket：用于客户端和服务器间的网络通信，看成不同主机的进程间的双向通信。
25. 线程类的构造方法、静态块是被哪个线程调用的
* 构造方法和静态块被new这个线程类所在的线程调用
* run里的代码被自身线程调用
* Thread2 中 new 了Thread1，main 函数中 new 了 Thread2，那么
  * Thread2 的构造方法、静态块是 main 线程调用的，Thread2 的 run()方法是Thread2 自己调用的；
  * Thread1 的构造方法、静态块是 Thread2 调用的，Thread1 的 run()方法是Thread1 自己调用的。
26. 进程调度和线程调度
  * 线程调度制度
    * 分时调度——所有线程轮流获得cpu使用权，均分时间片
    * 抢占式调度——让优先级高的线程抢占CPU，直到有更高优先级线程进入或线程任务运行。JVM默认。
  * 进程调度
    * FCFS 先来先服务：从就绪队列中选择最先进入队列的进程分配资源，直到执行完成或中断再重新调度。
    * SJF 短作业优先：从就绪队列中选择运行时间最短的进程分配资源，直到执行完成或中断再重新调度。
    * 高响应比优先：把CPU分配给就绪队列中响应比最高的进程。响应比 = (等待时间 + 要求服务时间)/ 要求服务时间。FCFS 和 SJF 的折中方案。
    * RR 时间片轮转：每个进程被分配一个时间片，若时间片结束进程仍在运行，则资源被剥夺给另一个进程。该进程被移到就绪进程列表队列的末尾，等待下一次分配。
    * 优先级：首先执行具有最高优先级的进程，若优先级相同则以 FCFS 方式执行，若有更高优先级进程传入，则中断去执行更高优先级。
    * 多级反馈队列：既能使高优先级的作业得到响应又能使短作业迅速完成。各个队列的时间片随着优先级的增加而减少。
27. 共享锁和非共享锁
  * 基于AQS实现
  * 非共享锁（只有一个线程能执行）——ReentrantLock。又分为公平和非公平。
  * 共享锁（多个线程执行）——如Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock
28. java的多线程模型
  * 多对一模型：多个用户线程映射到一个内核线程，用户线程的建立、同步、销毁和调度完全在用户态中完成，对内核透明。
      * 优点：
        * 线程的上下文切换都发生在用户控件，避免了模态切换，减少了性能的开销
        * 用户线程的创建不受内核资源的限制，可以支持更大规模的线程数量
      * 缺点：
        * 只有一个cpu，无法进行并行。
        * 增加了复杂度，所有的线程操作都需要用户程序自己处理
  * 一对一模型：每个用户线程都映射到一个内核线程，每个线程都是一个独立的调度单元，由内核调度器独立调度，一个线程的阻塞不会影响到其他线程。
      * 优点：
        * 每个线程都是一个独立的调度单元，使用内核提供的线程调度及处理器映射，可以完成线程的切换，充分利用多核处理器的优势，实现真正的并行。
      * 缺点：
        * 每创建一个用户级线程都需要创建一个内核级线程与其对应，因此需要消耗一定的内核资源,而内核资源是有限的，所以能创建的线程数量也是有限的
        * 需要进行系统调用的操作需要频繁的在用户态和内核态之间切换，开销大
  * 多对多模型：多个线程被映射到多个内核线程
      * 优点：
        * 用户线程的切换创建发生在用户空间，能创建数量更多的线程
        * 大部分线程的上下文切换都发生在用户空间，减少了模态切换带来的开销
        * 使用内核提供的线程调度功能，可以实现真正的并行，并降低了整个进程被完全阻塞的风险
  * 总结：java的线程是映射到操作系统的原生线程上的。不同的操作系统可能使用不同的线程模型，例如 Linux 和 windows 可能使用了一对一模型，solaris 和 unix 某些版本可能使用多对多模型。

