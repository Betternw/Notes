1. 数据库的四大特征，数据库的隔离级别？
   * 事务（Transaction）是并发控制的基本单位。是数据库维护数据一致性的单位，
   * 原子性 事务包含的所有操作要么全部成功，要么全部失败回滚。
   * 一致性 一个事务执行之前和执行之后都必须处于一致性状态。
   * 隔离性 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。
   * 持久性 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的。
2. 数据库设计中常讲的三范式是指什么？
   * 第一范式1NF 如果数据库表中的所有字段值都是不可分解的原子值，
   * 第二范式2NF(表中除主键外的字段都完全依赖主键)  (1)表中必须有主键；(2)其他非主属性必须完全依赖主键，不能只依赖主键的一部分（主要针对联合主键而言）。
   * 第三范式3NF 除主键外的字段都完全直接依赖，不能是传递依赖
3. count(*),count(1)和count(col)
   * 执行效果上
     * count(*)和count(1)相当于统计行数，不忽略列值为null的
     * count(col)统计col列，忽略null值
   * 执行效率上
     * count(*)mysql做了优化处理，有主键的情况下，效率更优
     * count(1)当没有主键时使用。
     * count(col)最慢，因为不走索引
4. 存储引擎MyISAM和InnoDB区别
   * InnoDB支持行+表级锁，MyISAM只支持表级锁
   * InnoDB支持事物，MyISAM不支持事务
   * InnoDB支持外键，MyISAM不支持外键
   * InnoDB支持MVCC，可以处理大量数据
5. 索引
* 索引是一种数据结构，提供指向存储在表的指定列中数据值的指针，能加快检索速度，但同时索引也需要空间存储和定期维护。(通俗理解为书本的目录)
* 类型
  * 主键索引：数据列不允许重复，不允许null，一个表主键唯一；
  * 唯一索引：数据列不允许重复，允许null，一个表允许多个唯一索引。
  * 普通索引：允许null，无唯一性要求。
  * 全文索引：搜索时使用。
* InnoDB索引类型
   * B+ Tree索引
     * InnoDB默认的索引方式。有序索引，将相邻数据都存在一起，把随机IO变成顺序IO。
     * B树(m阶) 一棵m阶B树是一棵平衡的m路搜索树。
       * 每个节点最多拥有m棵子树；
       * 根结点至少拥有两颗子树（存在子树的情况下);
       * 除了根结点以外，其余每个分支结点至少拥有 m/2 棵子树；
       * 所有的叶结点都在同一层上；
       * 有 k 棵子树的分支结点则存在 k-1 个关键码，关键码按照递增次序进行排列；
       * 关键字数量需要满足ceil(m/2)-1 <= n <= m-1；
     * B+树
       * 根结点只有一个，分支数量范围为[2，m]
       * 分支结点，每个结点包含分支数范围为[ceil(m/2), m]；
       * 分支结点的关键字数量等于其子分支的数量减一，关键字的数量范围为[ceil(m/2)-1, m-1]，关键字顺序递增；
       * 所有叶子结点都在同一层；
   * B树和B+树的区别
       * B树，叶子和非叶子节点都存放数据；B+树，只在叶子节点存放数据。
       * B+树的叶子节点有一条链相连，能进行顺序索引，而B树的叶子节点各自独立。
   * 数据库为什么用B+树
      * B+树支持随机和顺序索引，B树只支持随机索引；
      * B+树查询效率稳定。B+树数据存储在叶子结点中，B树存储在叶子 + 非叶子节点，所以B+树的查询是从root到叶子节点，不会中断。
      * B+树内部结点更小，非叶节点=指针+key，B树中非叶节点=指针+key+data，每个节点存储空间一定，B树key存储较少，导致B树的节点比B+树多，IO次数多。
   * 为什么MongoDB使用B树
      * MySQL是关系型数据库，更多使用范围查询，所以用B+树；
      * MongoDB是非关系型数据库，数据遍历的操作少，常用单一查询，所以用B树。
   * 为什么不用红黑树
      * B+ 树有更低的树高。平衡树的树高 O(h)=O(logdN)，其中 d 为每个节点的出度。红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多。磁盘IO次数和树高度成正比；
      * 磁盘预读特性：B+树有磁盘预读取的特性，每次建立节点时，会申请连续一段物理空间，从而做到一次IO读取一个节点；红黑树没有连续物理空间，只是逻辑相近节点。
   * 哈希索引
      * 类似哈希表，将数据库字段转换成hash值和行指针放进hash表。以O(1)时间搜索，但无法排序分组，只能精准查找。
      * 自适应哈希索引：当某个索引被频繁引用时，在B+树索引上再创建一个哈希索引，提供快速查找。

* 聚簇索引(主索引)和非聚簇索引(辅助索引)
   * B+ Tree索引分为主索引和辅助索引。
   * 聚簇索引/主索引：叶子结点存储数据。直接找key就能获得数据。一个表只能包含一个主索引。相当于以主键创建的索引。物理上连续。
   * 当定义了主键后，InnoDB会利用主键来生成其聚簇索引；
   * 如果没有主键，InnoDB会选择一个非空的唯一索引来创建聚簇索引；
   * 如果这也没有，InnoDB会隐式的创建一个自增的列(rowid)来作为聚簇索引。
   * 非聚簇索引/辅助索引：叶子结点存储主键的值。需要先取得主键，再用此主键走一遍主索引。(回表，若全部命中索引，也可以不用回表)逻辑上连续。
   * 使用主键作为”指针”会占用更多空间，但当行移动或者数据页分裂时不需要更新辅助索引，若用地址值，每次都要更新。
* 索引优化
  * 索引列顺序：把选择性最强/使用最频繁的索引放在前面。索引选择性=不重复的索引值 / 记录总数。
  * 覆盖索引：覆盖索引是select的数据列只用从索引中就能够取得，不必读取数据行，即查询列要被所建的索引覆盖。
  * 前缀索引：根据选择性，只索引字符串的最左M个字符，前提是前缀的标识度高。
  * 索引下推：联合索引时，先对其余其他字段判断，过滤不满足条件的记录，减少回表次数和数据数量。
  * 最左前缀匹配原则：联合索引时，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)停止，所以要注意联合索引的顺序。
* SQL语句
```java
//增加索引
alter table user add index/unique/fulltext user_id(id) 
create index/unique user_id on user(id)

//删除索引
alter table user drop key user_id
```

* 小知识
   * 回表:回表就是指普通索引查询，先搜索普通索引树获得主键值，再到主键索引树搜索一次。
   * 百万级数据删除:百万级以上的数据一定存在索引，CRUD时都会对索引有影响，所以先删除索引，再删无用数据，循环。
   * 索引失效
      * or 关键字；
      * like开头%；
      * 字符串类型的列，要将数据用双引号引用，否则索引失效；
      * where 中索引列有函数或运算
6. 事务
事务就是逻辑上的一组操作，要么都执行，要么都不执行，执行结果必须让数据库从一种一致性状态到另一种一致性状态。
* 四大特性ACID
   * ACID。
   * 原子性(Atomicity)：事务是最小的执行单位，要么全部执行，要么全部不执行。
   * 一致性(Consistency)：保证数据库状态要一致，多个事务对同一数据读取结果是相同的。
   * 隔离性(Isolation)：多个事务并发，各个事务是不受其他事务干扰的。
   * 持久性(Durability)：一个事务一旦提交，此修改在数据库中是持久保存的。
   * 持久性应对系统GG，只有一致性才能保证执行结果正确，并发才要隔离性，原子性是最基础的。
* 并发事务的问题
   * 脏读(Dirty read)：事务A读取了事务B修改未提交的数据，B回滚，A的数据不一致。
   * 丢失修改(Lost to modify)：事务A和B同时读取数据，A修改后先提交，B修改后再提交会将A的修改覆盖。
   * 不可重复读(Unrepeatable read)：事务A两次读取数据间，有事务B修改更新，导致两次读取数据不一致。
   * 幻读(Phantom read)：事务A两次读取数据间，有事务B增加了记录，导致两次读取数据记录数不一致。
   * 注：幻读指结构上发生变化。不可重复读指数值上发生变化。

* 隔离级别
   * 读未提交(Read-Uncommitted)：最低级别，允许读取尚未提交的数据。会发生脏读、幻读、不可重复读。
   * 读已提交(Read-Committed)：允许读取已经提交的数据。阻止脏读。oracle默认
   * 可重复读(Repeatable-Read)：读事务时禁止写事务，写事务时阻止一切。阻止脏读和不可重复读。InnoDB默认隔离级别。
   * 可串行化(Serialization)：最高级别。所有事务依次执行，不会互相干扰。阻止三个事务问题。
7. 锁机制
锁机制是在并发时，确保数据访问次序的。
* 按粒度分
   * 分为表级锁，行级锁和页级锁。
   * 表级锁：粒度最大的锁。对整张表加锁，资源消耗少，加锁快，不会死锁，但锁冲突概率高。
   * 行级锁：粒度最小的锁。对当前操作行加锁，加锁慢，开销大，会死锁，但大大减少冲突。
   * 页级锁：介于行级锁和表级锁中间的锁。一次锁定相邻的一组记录，会死锁，其他均属于中等。
* 常见行级锁
   * Record Lock：单行锁，锁定符合条件的行。
   * Gap Lock：间隙锁，锁定一个范围，不含记录本身。防止幻读。
   * Next-key Lock：Record+Gap，锁定一个范围，含记录本身。
* 表级锁使用场景——当事务比较复杂，使用行级锁容易死锁回滚。更新大表的大部分数据，表级锁效率更好。
* 行级锁何时会锁住整张表——更新的列没有建立索引，会直接锁住整张表。
* 按是否可写分
   * 共享锁(Shared Lock)：读锁。锁定的资源能被其他用户读取，但不能修改，直到资源上的S锁全部被释放。
   * 排他锁(Exclusive Lock)：写锁。事务T对数据A加X锁，则只允许T读取修改，直到X锁释放。在更新操作，如insert、update 或 delete时，始终应用排它锁。
* 死锁
   * MySQL中的死锁是多个事务使用行级锁对某行数据加锁造成。
   * 解决方案
      * 指定锁的获取资源顺序。(操作系统中的哲学家就餐问题)
      * 同一个事务一次锁定尽可能多的资源。
      * 事务拆分成小事务。
      * 设置超时时间。InnoDB默认是50s。
      * 开启死锁检测。发生死锁时，回归死锁链上一个事务，让其他事务继续执行。
* 悲观锁和乐观锁
   * 悲观锁和乐观锁是数据库管理系统并发控制的手段。
   * 悲观锁：利用数据库的锁机制实现，在整个数据处理过程都加锁，保证排他性。
   * 乐观锁：CAS/版本号实现。假定不会发生冲突，在提交时检查是否违反数据完整性。
   * 乐观锁的ABA问题
     * 加入数据版本记录机制——每次变量更新都将版本号加1，或者使用时间戳。
     * ABA问题：事务X读取数据A时，事务Y修改成B，又修改回A，事实上数据发生过改变的，存在并发问题，但事务X无法得到数据发生过变化。
   * 使用场景
     * 多读用乐观，多写用悲观。
8. MySQL架构和执行流程
* 基础架构
   * MySQL主要分为Server层和存储引擎层。
   * Server层：跨存储引擎的功能都在此实现，如视图、触发器、函数等，有一个binlog日志。
   * 存储引擎：负责数据的存储和读取。常用的是InnoDB，自带redolog模块。
* 基本组件
   * Server层有五个主要组件。
   * 连接器：身份验证和权限设置。
   * 查询缓存：执行查询语句前，先查有没有缓存的结果集。(8.0后废弃)
   * 分析器：没有命中缓存，则进入分析器进行词法和语法分析。
   * 优化器：按照MySQL认为最优的方案执行。
   * 执行器：用户有权限，则调用存储引擎，执行语句。
* 执行流程
   * 查询语句
     * 权限校验—->查询缓存—->分析器—->优化器—->权限校验—->执行器—->引擎
   * 更新语句
     * 分析器—->权限校验—->执行器—->引擎—->redo log prepare—->binlog—->redo log commit

   * 以修改张三的年龄为例：
      先查询到张三这条数据，如果有缓存，用缓存。
      拿到查询的语句，把 age 改为 19。
      调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态。
      通知执行器，执行完成，可以提交。
      执行器收到通知后记录 binlog，调用引擎接口，提交 redo log 为提交状态。
      更新完成。
* 日志模块
   * MySQL主要有redolog和binlog。
     * redolog(重做日志)：InnoDB特有，物理日志。记录哪个数据页做了修改。
     * binlog(归档日志)：Server层自带，逻辑日志，记录本次修改的SQL语句。通常使用row二进制格式，保证数据记录的准确性。
* 两阶段提交
   * 保证数据一致性。
   * redolog prepare引擎数据保存 -> binlog执行器收到信号 -> redolog commit执行器调用
   * 异常时，MySQL先判断redolog是否完整，完整则直接提交。redolog只是prepare状态，查看binlog是否完整，完整就继续提交redolog，否则回滚事务。
* MySQL为什么会突然慢一下
  * 更新数据库时，先写日志，等合适时间再更新磁盘。当redolog写满，需要flush脏页，将数据写入磁盘，这是会使执行速度慢一下。
9. 多版本并发控制
* MVCC 多版本并发控制是 InnoDB 实现隔离级别的方式，用于读已提交和可重复读。
   * Next-Key Locks 解决幻读，锁自己Record+锁范围Gap。
* 基本思想
   * 事务的修改操作会为数据行新增一个版本快照，写操作更新最新的版本快照，读操作去读旧版本快照。
   * 注：脏读和不可重复读的原因是事务读取到其他事务未提交的修改。
* Undo日志
   * 多版本就是指多个版本的快照，快照存储在 Undo 日志中，通过回滚指针把一个数据行的所有快照连接起来。
   * 系统版本号SYS_ID：递增数字，每一个新事务，就++；
   * 事务版本号TRX_ID：事务开始时的系统版本号。
* ReadView
   * MVCC 维护了 ReadView 结构，包含当前系统未提交的事务列表TRX_IDs，列表的最大值和最小值。
* SELECT
   * 根据数据行快照的 TRX_ID 与 TRX_ID_MIN 和 TRX_ID_MAX 之间的关系，从而判断数据行快照是否可以使用：
   * TRX_ID < TRX_ID_MIN，表示该数据行快照是在当前所有未提交事务之前进行更改的，因此可以使用。
   * TRX_ID > TRX_ID_MAX，表示该数据行快照是在事务启动之后被更改的，因此不可使用。
   * TRX_ID_MIN <= TRX_ID <= TRX_ID_MAX，需要根据隔离级别再进行判断：
     * 提交读：如果 TRX_ID 在 TRX_IDs 列表中，表示该数据行快照对应的事务还未提交，则该快照不可使用。否则表示已经提交，可以使用。
     * 可重复读：都不可以使用。因为如果可以使用的话，那么其它事务也可以读到这个数据行快照并进行修改，那么当前事务再去读这个数据行得到的值就会发生改变，也就是出现了不可重复读问题。
   * 在数据行快照不可使用的情况下，需要沿着 Undo Log 的回滚指针 ROLL_PTR 找到下一个快照，再进行上面的判断。
10. 优化
* 结构优化
   * 拆表。把使用频率低的列单独分离成表。
   * 增加中间表。把经常联合查询数据插入中间表。
   * 增加冗余字段。
* SQL优化
   * 超大分页
     * 减少load的数据，如先定位id再关联；
     * 增加缓存，如redis。
   * 慢查询日志
     * 当执行时间超过临界值时，将SQL计入日志。慢查询优化主要从三方面入手。
load了额外数据；
没有命中索引；
数据量太大，需要切分。
8.2.3 语句优化
参考 https://www.cnblogs.com/huchong/p/10219318.html 作者：听风。

8.3 大表优化
答：单表记录数过大时，数据库性能下降明显，需要进行一系列的优化。

8.3.1 限定数据范围
最简单的手段，限制数据范围条件来查询数据。

8.3.2 读写分离
主服务器处理写操作或实时性高的读操作，从服务器处理读操作。

实现方式：增设代理服务器，决定将应用传来的请求转发到哪个服务器。
原因：极大减少了锁的争用；用冗余换可用性；从服务器可用MyISAM节约资源。
主从数据库
8.3.3 缓存
对基本不更新的数据使用应用级别的缓存。

8.3.4 水平拆分
水平拆分将一张表A拆分成多个相同结构的表a1,a2,a3存储，每个子表只占一部分数据。
又细分为库内分表和分库分表。

库内分表：子表仍在一个数据库实例中，仍要竞争同一个物理机资源。
分库分表：子表分散在不同数据库中。
优点：业务改造简单；解决了单表数据量过大的问题。
缺点：跨库的一致性难保证；join关联性能差；扩容和维护难度过大。

8.3.5 垂直拆分
又细分为垂直分库和垂直分表。

垂直分库：基于业务划分数据库，让每个业务都有独立数据库。
垂直分表：基于数据表的列切分，把一张列1-7的表拆成列1-4和列1 5-7的表。
优点：业务解耦；高并发下提升了性能。
缺点：增加了业务复杂度；主键冗余；数据量过大仍未解决，需要配合水平拆分。

8.4 拆分后的问题
事务一致性
两阶段提交性能较差。通常追求最终一致性，出现问题进行事务补偿。
分页和排序
字段排序，需要先在每个节点内排序，再将结果汇总再次排序，最后返回给用户。
全局唯一主键
拆分后属于分布式应用，需要使用分布式ID用作全局唯一主键。一般用雪花模型。
注：所以推荐使用成熟的中间件，如sharding-jdbc，Atlas，Cobar

8.5 分布式ID
UUID：生成简单，但不推荐！长度过长，不适合实际的业务需求。
public static void main(String[] args) { 
       String uuid = UUID.randomUUID().toString().replaceAll("-","");
       System.out.println(uuid);
 }
数据库自增ID：用一个单独数据库实例生成ID，需要ID时，向表中插入记录并返回ID。
MySQL本身性能是瓶颈，而且存在宕机风险。
数据库集群：对每个MySQL实例的自增ID设置起始值和自增步长，保证不冲突。
后续扩容问题大，无法满足高并发。
数据库号段模式：每次从数据库获取一个号段范围，具体业务将号段生成对应自增ID加载到内存。一批号段ID用完，再向数据库申请新的。
用版本号乐观锁更新；不频繁访问数据库。
雪花算法：twitter公司开源的算法。
Snowflake生成Long型64位ID。
组成结构：正数位（1bit，默认0）+ 时间戳（41bit，存储 当前-固定开始 的差值）+ 机器ID（5bit）+ 数据中心（5bit）+ 自增值（12bit，1ms支持同一节点生成4096个ID）